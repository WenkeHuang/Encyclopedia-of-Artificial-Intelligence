# 奇异值分解

关键词：奇异值分解、低秩逼近

矩阵的奇异值分解（singular value decomposition，简称SVD）是线性代数中很重要的内容，并且奇异值分解过程也是线性代数中相似对角化分解（也被称为特征值分解，eigenvalue decomposition，简称EVD）的延伸。

# 矩阵分解

给定一个大小为$m \times m $的矩阵![[公式]](https://www.zhihu.com/equation?tex=A)（是方阵），其对角化分解可以写成
$$
A = U \Lambda U ^{-1}
$$
其中，![[公式]](https://www.zhihu.com/equation?tex=U)的每一列都是特征向量，![[公式]](https://www.zhihu.com/equation?tex=%5CLambda)对角线上的元素是从大到小排列的特征值，若将![[公式]](https://www.zhihu.com/equation?tex=U)记作![[公式]](https://www.zhihu.com/equation?tex=U%3D%5Cleft%28+%5Cvec%7Bu%7D_1%2C%5Cvec%7Bu%7D_2%2C...%2C%5Cvec%7Bu%7D_m+%5Cright%29+)，则

![[公式]](https://www.zhihu.com/equation?tex=AU%3DA%5Cleft%28%5Cvec%7Bu%7D_1%2C%5Cvec%7Bu%7D_2%2C...%2C%5Cvec%7Bu%7D_m%5Cright%29%3D%5Cleft%28%5Clambda_1+%5Cvec%7Bu%7D_1%2C%5Clambda_2+%5Cvec%7Bu%7D_2%2C...%2C%5Clambda_m+%5Cvec%7Bu%7D_m%5Cright%29)

![[公式]](https://www.zhihu.com/equation?tex=%3D%5Cleft%28%5Cvec%7Bu%7D_1%2C%5Cvec%7Bu%7D_2%2C...%2C%5Cvec%7Bu%7D_m%5Cright%29+%5Cleft%5B+%5Cbegin%7Barray%7D%7Bccc%7D+%5Clambda_1+%26+%5Ccdots+%26+0+%5C%5C+%5Cvdots+%26+%5Cddots+%26+%5Cvdots+%5C%5C+0+%26+%5Ccdots+%26+%5Clambda_m+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)

![[公式]](https://www.zhihu.com/equation?tex=%5CRightarrow+AU%3DU%5CLambda+%5CRightarrow+A%3DU%5CLambda+U%5E%7B-1%7D)

更为特殊的是，当矩阵![[公式]](https://www.zhihu.com/equation?tex=A)是一个对称矩阵时，则存在一个对称对角化分解，即

![[公式]](https://www.zhihu.com/equation?tex=A%3DQ%5CLambda+Q%5ET)

其中，![[公式]](https://www.zhihu.com/equation?tex=Q)的每一列都是相互正交的特征向量，且是单位向量，![[公式]](https://www.zhihu.com/equation?tex=%5CLambda)对角线上的元素是从大到小排列的特征值。

当然，将矩阵![[公式]](https://www.zhihu.com/equation?tex=Q)记作![[公式]](https://www.zhihu.com/equation?tex=Q%3D%5Cleft%28%5Cvec%7Bq%7D_1%2C%5Cvec%7Bq%7D_2%2C...%2C%5Cvec%7Bq%7D_m%5Cright%29)，则矩阵![[公式]](https://www.zhihu.com/equation?tex=A)也可以写成如下形式：

![[公式]](https://www.zhihu.com/equation?tex=A%3D%5Clambda_1+%5Cvec%7Bq%7D_1%5Cvec%7Bq%7D_1%5ET%2B%5Clambda_2+%5Cvec%7Bq%7D_2%5Cvec%7Bq%7D_2%5ET%2B...%2B%5Clambda_m+%5Cvec%7Bq%7D_m%5Cvec%7Bq%7D_m%5ET)

举一个简单的例子，如给定一个大小为![[公式]](https://www.zhihu.com/equation?tex=2%5Ctimes+2)的矩阵![[公式]](https://www.zhihu.com/equation?tex=A%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+2+%26+1+%5C%5C+1+%26+2+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)，根据

![[公式]](https://www.zhihu.com/equation?tex=%5Cleft%7C%5Clambda+I-A%5Cright%7C%3D%5Cleft%7C+%5Cbegin%7Barray%7D%7Bcc%7D+%5Clambda-2+%26+-1+%5C%5C+-1+%26+%5Clambda-2+%5C%5C+%5Cend%7Barray%7D+%5Cright%7C%3D0)求得特征值为![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_1%3D3)，![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_2%3D1)，相应地，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_1%3D%5Cleft%28%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D%2C+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D%5Cright%29%5ET)，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_2%3D%5Cleft%28-%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D%2C+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D%5Cright%29%5ET)，则

![[公式]](https://www.zhihu.com/equation?tex=A%3D%5Clambda_1+%5Cvec%7Bq%7D_1%5Cvec%7Bq%7D_1%5ET%2B%5Clambda_2+%5Cvec%7Bq%7D_2%5Cvec%7Bq%7D_2%5ET+%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+2+%26+1+%5C%5C+1+%26+2+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D).
这样，我们就很容易地得到了矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的对称对角化分解

# 奇异值分解的定义

在上面，对于对称的方阵而言，我们能够进行对称对角化分解，试想：对称对角化分解与奇异值分解有什么本质关系呢？

当给定一个大小为![[公式]](https://www.zhihu.com/equation?tex=m%5Ctimes+n)的矩阵![[公式]](https://www.zhihu.com/equation?tex=A)，虽然矩阵![[公式]](https://www.zhihu.com/equation?tex=A)不一定是方阵，但大小为![[公式]](https://www.zhihu.com/equation?tex=m%5Ctimes+m)的![[公式]](https://www.zhihu.com/equation?tex=AA%5ET)和![[公式]](https://www.zhihu.com/equation?tex=n%5Ctimes+n)的![[公式]](https://www.zhihu.com/equation?tex=A%5ETA)却是对称矩阵，若![[公式]](https://www.zhihu.com/equation?tex=AA%5ET%3DP%5CLambda_1+P%5ET)，![[公式]](https://www.zhihu.com/equation?tex=A%5ETA%3DQ%5CLambda_2Q%5ET)，则矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的奇异值分解为
![[公式]](https://www.zhihu.com/equation?tex=A%3DP%5CSigma+Q%5ET)

其中，矩阵![[公式]](https://www.zhihu.com/equation?tex=P%3D%5Cleft%28%5Cvec%7Bp%7D_1%2C%5Cvec%7Bp%7D_2%2C...%2C%5Cvec%7Bp%7D_m%5Cright%29)的大小为![[公式]](https://www.zhihu.com/equation?tex=m%5Ctimes+m)，列向量![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bp%7D_1%2C%5Cvec%7Bp%7D_2%2C...%2C%5Cvec%7Bp%7D_m)是![[公式]](https://www.zhihu.com/equation?tex=AA%5ET)的特征向量，也被称为矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的**左奇异向量**（left singular vector）；矩阵![[公式]](https://www.zhihu.com/equation?tex=Q%3D%5Cleft%28%5Cvec%7Bq%7D_1%2C%5Cvec%7Bq%7D_2%2C...%2C%5Cvec%7Bq%7D_n%5Cright%29)的大小为![[公式]](https://www.zhihu.com/equation?tex=n%5Ctimes+n)，列向量![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_1%2C%5Cvec%7Bq%7D_2%2C...%2C%5Cvec%7Bq%7D_n)是![[公式]](https://www.zhihu.com/equation?tex=A%5ETA)的特征向量，也被称为矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的**右奇异向量**（right singular vector）；矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_1)大小为![[公式]](https://www.zhihu.com/equation?tex=m%5Ctimes+m)，矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_2)大小为![[公式]](https://www.zhihu.com/equation?tex=n%5Ctimes+n)，两个矩阵对角线上的非零元素相同（即矩阵![[公式]](https://www.zhihu.com/equation?tex=AA%5ET)和矩阵![[公式]](https://www.zhihu.com/equation?tex=A%5ETA)的非零特征值相同）；矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CSigma)的大小为![[公式]](https://www.zhihu.com/equation?tex=m%5Ctimes+n)，位于对角线上的元素被称为**奇异值**（singular value）。



接下来，我们来看看矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CSigma)与矩阵![[公式]](https://www.zhihu.com/equation?tex=AA%5ET)和矩阵![[公式]](https://www.zhihu.com/equation?tex=A%5ETA)的关系。令常数![[公式]](https://www.zhihu.com/equation?tex=k)是矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的秩，则![[公式]](https://www.zhihu.com/equation?tex=k%5Cleq+%5Cmin%5Cleft%28+m%2Cn+%5Cright%29+)，当![[公式]](https://www.zhihu.com/equation?tex=m%5Cne+n)时，很明显，矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_1)和矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_2)的大小不同，但矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_1)和矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_2)对角线上的非零元素却是相同的，若将矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_1)（或矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_2)）对角线上的非零元素分别为![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_1%2C%5Clambda_2%2C...%2C%5Clambda_k)，其中，这些特征值也都是非负的，再令矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CSigma)对角线上的非零元素分别为![[公式]](https://www.zhihu.com/equation?tex=%5Csigma_1%2C%5Csigma_2%2C...%2C%5Csigma_k)，则
![[公式]](https://www.zhihu.com/equation?tex=%5Csigma_1%3D%5Csqrt%7B%5Clambda_1%7D%2C%5Csigma_2%3D%5Csqrt%7B%5Clambda_2%7D%2C...%2C%5Csigma_k%3D%5Csqrt%7B%5Clambda_k%7D)

即非零奇异值的平方对应着矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_1)（或矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CLambda_2)）的非零特征值，到这里，我们就不难看出奇异值分解与对称对角化分解的关系了，即我们可以由对称对角化分解得到我们想要的奇异值分解。

为了便于理解，在这里，给定一个大小为![[公式]](https://www.zhihu.com/equation?tex=2%5Ctimes+2)的矩阵![[公式]](https://www.zhihu.com/equation?tex=A%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+4+%26+4+%5C%5C+-3+%26+3+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)，虽然这个矩阵是方阵，但却不是对称矩阵，我们来看看它的奇异值分解是怎样的。

由![[公式]](https://www.zhihu.com/equation?tex=AA%5ET%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+32+%26+0+%5C%5C+0+%26+18+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)进行对称对角化分解，得到特征值为![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_1%3D32)，![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_2%3D18)，相应地，特征向量为![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bp%7D_1%3D%5Cleft%28+1%2C0+%5Cright%29+%5ET)，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bp%7D_2%3D%5Cleft%280%2C1%5Cright%29%5ET)；由![[公式]](https://www.zhihu.com/equation?tex=A%5ETA%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+25+%26+7+%5C%5C+7+%26+25+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)进行对称对角化分解，得到特征值为![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_1%3D32)，![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_2%3D18)，相应地，特征向量为![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_1%3D%5Cleft%28%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D%2C%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D%5Cright%29%5ET)，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_2%3D%5Cleft%28-%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D%2C+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D%5Cright%29%5ET)。取![[公式]](https://www.zhihu.com/equation?tex=%5CSigma+%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+4%5Csqrt%7B2%7D+%26+0+%5C%5C+0+%26+3%5Csqrt%7B2%7D+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)，则矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的奇异值分解为

![[公式]](https://www.zhihu.com/equation?tex=A%3DP%5CSigma+Q%5ET%3D%5Cleft%28%5Cvec%7Bp%7D_1%2C%5Cvec%7Bp%7D_2%5Cright%29%5CSigma+%5Cleft%28%5Cvec%7Bq%7D_1%2C%5Cvec%7Bq%7D_2%5Cright%29%5ET)

![[公式]](https://www.zhihu.com/equation?tex=%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+1+%26+0+%5C%5C+0+%26+1+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D+%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+4%5Csqrt%7B2%7D+%26+0+%5C%5C+0+%26+3%5Csqrt%7B2%7D+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D+%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D+%26+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D+%5C%5C+-%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D+%26+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B2%7D+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D+%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+4+%26+4+%5C%5C+-3+%26+3+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D).

若矩阵![[公式]](https://www.zhihu.com/equation?tex=A)不再是一个方阵，而是一个大小为![[公式]](https://www.zhihu.com/equation?tex=3%5Ctimes+2)的![[公式]](https://www.zhihu.com/equation?tex=A%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+1+%26+2+%5C%5C+0+%26+0+%5C%5C+0+%26+0+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)，由![[公式]](https://www.zhihu.com/equation?tex=AA%5ET%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bccc%7D+5+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)得到特征值为![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_1%3D5)，![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_2%3D%5Clambda_3%3D0)，特征向量为![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bp%7D_1%3D%5Cleft%281%2C0%2C0%5Cright%29%5ET)，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bp%7D_2%3D%5Cleft%280%2C1%2C0%5Cright%29%5ET)，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bp%7D_3%3D%5Cleft%280%2C0%2C1%5Cright%29%5ET)；由![[公式]](https://www.zhihu.com/equation?tex=A%5ETA%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+1+%26+2+%5C%5C+2+%26+4+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)得到特征值为![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_1%3D5)，![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_2%3D0)，特征向量为![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_1%3D%5Cleft%28%5Cfrac%7B%5Csqrt%7B5%7D%7D%7B5%7D%2C%5Cfrac%7B2%5Csqrt%7B5%7D%7D%7B5%7D%5Cright%29%5ET)，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_2%3D%5Cleft%28-%5Cfrac%7B2%5Csqrt%7B5%7D%7D%7B5%7D%2C%5Cfrac%7B%5Csqrt%7B5%7D%7D%7B5%7D%5Cright%29%5ET)，令![[公式]](https://www.zhihu.com/equation?tex=%5CSigma%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+%5Csqrt%7B5%7D+%26+0+%5C%5C+0+%26+0+%5C%5C+0+%26+0+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)（注意：矩阵![[公式]](https://www.zhihu.com/equation?tex=%5CSigma)大小为![[公式]](https://www.zhihu.com/equation?tex=3%5Ctimes+2)），此时，矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的奇异值分解为

![[公式]](https://www.zhihu.com/equation?tex=A%3DP%5CSigma+Q%5ET%3D%5Cleft%28%5Cvec%7Bp%7D_1%2C%5Cvec%7Bp%7D_2%5Cright%29%5CSigma+%5Cleft%28%5Cvec%7Bq%7D_1%2C%5Cvec%7Bq%7D_2%5Cright%29%5ET)

![[公式]](https://www.zhihu.com/equation?tex=%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bccc%7D+1+%26+0+%26+0+%5C%5C+0+%26+1+%26+0+%5C%5C+0+%26+0+%26+1+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D+%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+%5Csqrt%7B5%7D+%26+0+%5C%5C+0+%26+0+%5C%5C+0+%26+0+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D+%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+%5Cfrac%7B%5Csqrt%7B5%7D%7D%7B5%7D+%26+%5Cfrac%7B2%5Csqrt%7B5%7D%7D%7B5%7D+%5C%5C+-%5Cfrac%7B2%5Csqrt%7B5%7D%7D%7B5%7D+%26+%5Cfrac%7B%5Csqrt%7B5%7D%7D%7B5%7D+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D+%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bcc%7D+1+%26+2+%5C%5C+0+%26+0+%5C%5C+0+%26+0+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)

# 奇异值分解的低秩逼近

在对称对角化分解中，若给定一个大小为![[公式]](https://www.zhihu.com/equation?tex=3%5Ctimes+3)的矩阵![[公式]](https://www.zhihu.com/equation?tex=A%3D%5Cleft%5B+%5Cbegin%7Barray%7D%7Bccc%7D+30+%26+0+%26+0+%5C%5C+0+%26+20+%26+0+%5C%5C+0+%26+0+%26+1+%5C%5C+%5Cend%7Barray%7D+%5Cright%5D)，很显然，矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的秩为![[公式]](https://www.zhihu.com/equation?tex=rank%5Cleft%28A%5Cright%29%3D3)，特征值为![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_1%3D30)，![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_2%3D20)，![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_3%3D1)，对应的特征向量分别为![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_1%3D%5Cleft%281%2C0%2C0%5Cright%29%5ET)，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_2%3D%5Cleft%280%2C1%2C0%5Cright%29%5ET)，![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_3%3D%5Cleft%280%2C0%2C1%5Cright%29%5ET)，考虑任意一个向量![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bv%7D%3D%5Cleft%282%2C4%2C6%5Cright%29%5ET%3D2%5Cvec%7Bq%7D_1%2B4%5Cvec%7Bq%7D_2%2B6%5Cvec%7Bq%7D_3)，则

![[公式]](https://www.zhihu.com/equation?tex=A%5Cvec%7Bv%7D%3DA%5Cleft%282%5Cvec%7Bq%7D_1%2B4%5Cvec%7Bq%7D_2%2B6%5Cvec%7Bq%7D_3%5Cright%29)

![[公式]](https://www.zhihu.com/equation?tex=%3D2%5Clambda_1%5Cvec%7Bq%7D_1%2B4%5Clambda_2%5Cvec%7Bq%7D_2%2B6%5Clambda_3%5Cvec%7Bq%7D_3%3D60%5Cvec%7Bq%7D_1%2B80%5Cvec%7Bq%7D_2%2B6%5Cvec%7Bq%7D_3)

在这里，我们会发现，即使![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bv%7D)是一个任意向量，用矩阵![[公式]](https://www.zhihu.com/equation?tex=A)去乘以![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bv%7D)的效果取决于![[公式]](https://www.zhihu.com/equation?tex=A)较大的特征值及其特征向量，类似地，在奇异值分解中，较大的奇异值会决定原矩阵的“主要特征”，下面我们来看看奇异值分解的低秩逼近（有时也被称为截断奇异值给定一个大小为![[公式]](https://www.zhihu.com/equation?tex=m%5Ctimes+n)的矩阵![[公式]](https://www.zhihu.com/equation?tex=A)，由于![[公式]](https://www.zhihu.com/equation?tex=A%3DP%5CSigma+Q%5ET)可以写成

![[公式]](https://www.zhihu.com/equation?tex=A%3D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7B%5Csigma_i%5Cvec%7Bp%7D_i%5Cvec%7Bq%7D_i%5ET%7D%3D%5Csigma_1%5Cvec%7Bp%7D_1%5Cvec%7Bq%7D_1%5ET%2B%5Csigma_2%5Cvec%7Bp%7D_2%5Cvec%7Bq%7D_2%5ET%2B...%2B%5Csigma_k%5Cvec%7Bp%7D_k%5Cvec%7Bq%7D_k%5ET)

其中，向量![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bp%7D_1%2C%5Cvec%7Bp%7D_2%2C...%2C%5Cvec%7Bp%7D_k)之间相互正交，向量![[公式]](https://www.zhihu.com/equation?tex=%5Cvec%7Bq%7D_1%2C%5Cvec%7Bq%7D_2%2C...%2C%5Cvec%7Bq%7D_k)之间也相互正交，由内积![[公式]](https://www.zhihu.com/equation?tex=%5Cleft%3C%5Csigma_i%5Cvec%7Bp%7D_i%5Cvec%7Bq%7D_i%5ET%2C%5Csigma_j%5Cvec%7Bp%7D_j%5Cvec%7Bq%7D_j%5ET%5Cright%3E%3D0%2C1%5Cleq+i%5Cleq+k%2C1%5Cleq+j%5Cleq+k%2Ci%5Cne+j)得到矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的F-范数的平方为分解）

![[公式]](https://www.zhihu.com/equation?tex=%7C%7CA%7C%7C_F%5E2%3D%7C%7C%5Csigma_1%5Cvec%7Bp%7D_1%5Cvec%7Bq%7D_1%5ET%2B%5Csigma_2%5Cvec%7Bp%7D_2%5Cvec%7Bq%7D_2%5ET%2B...%2B%5Csigma_k%5Cvec%7Bp%7D_k%5Cvec%7Bq%7D_k%5ET%7C%7C_F%5E2)![[公式]](https://www.zhihu.com/equation?tex=%3D%5Csigma_1%5E2%7C%7C%5Cvec+p_1%5Cvec+q_1%5ET%7C%7C_F%5E2%2B%5Csigma_2%5E2%7C%7C%5Cvec+p_2%5Cvec+q_2%5ET%7C%7C_F%5E2%2B...%2B%5Csigma_k%5E2%7C%7C%5Cvec+p_k%5Cvec+q_k%5ET%7C%7C_F%5E2)![[公式]](https://www.zhihu.com/equation?tex=%3D%5Csigma_1%5E2%2B%5Csigma_2%5E2%2B...%2B%5Csigma_k%5E2%3D%5Csum_%7Bi%3D1%7D%5E%7Br%7D%7B%5Csigma_i%5E2%7D)

知道了矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的F-范数的平方等于其所有奇异值的平方和之后，假设![[公式]](https://www.zhihu.com/equation?tex=A_1%3D%5Csigma_1%5Cvec+p_1%5Cvec+q_1%5ET)是矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的一个秩一逼近（rank one approximation），那么，它所带来的误差则是![[公式]](https://www.zhihu.com/equation?tex=%5Csigma_2%5E2%2B%5Csigma_3%5E2%2B...%2B%5Csigma_k%5E2)（![[公式]](https://www.zhihu.com/equation?tex=k)是矩阵![[公式]](https://www.zhihu.com/equation?tex=A)的秩），![[公式]](https://www.zhihu.com/equation?tex=A_1%3D%5Csigma_1%5Cvec+p_1%5Cvec+q_1%5ET)是最好的秩一逼近。

# SVD的一些性质

对于奇异值,它跟我们特征分解中的特征值类似，在奇异值矩阵中也是按照从大到小排列，而且奇异值的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上的比例。也就是说，我们也可以用最大的k个的奇异值和对应的左右奇异向量来近似描述矩阵。也就是说：
$$
A_{m \times n} = U_{m \times m}\Sigma_{m \times n} V^T_{n \times n} \approx U_{m \times k}\Sigma_{k \times k} V^T_{k \times n}
$$
其中k要比n小很多，也就是一个大的矩阵A可以用三个小的矩阵$U_{m \times k},\Sigma_{k \times k} ,V^T_{k \times n}$来表示。如下图所示，现在我们的矩阵A只需要灰色的部分的三个小矩阵就可以近似描述了。

![SVD](../img/ML/SVD.png)

由于这个重要的性质，SVD可以用于PCA降维，来做数据压缩和去噪。也可以用于推荐算法，将用户和喜好对应的矩阵做特征分解，进而得到隐含的用户需求来做推荐。同时也可以用于NLP中的算法，比如潜在语义索引（LSI）。下面我们就对SVD用于PCA降维做一个介绍。







