## Improving Federated Learning Personalization via Model Agnostic Meta Learning

### Problems

FL applications generally face non-i.i.d and unbalanced data available to devices, which makes it challenging to ensure good performance across different devices with a FL-trained global model.

### Contribution

- The popular FL algorithm, Federated Averaging, can be interpreted as a meta learning algorithm. FedAvg可以被解释成元学习算法

- Careful fine-tuning can yield a global model with higher accuracy, which is at the same time easier to personalize. However, solely optimizing for the global model accuracy yields a weaker personalization result.  仔细的微调可以生成具有更高准确度的全局模型，同时更易于个性化。 但是，仅针对全局模型精度进行优化会产生较弱的个性化结果

- A model trained using a standard datacenter optimization method is much harder to personalize, compared to one trained using Federated Averaging, supporting the first claim. 与使用联邦平均法训练的模型相比，使用标准数据中心优化方法训练的模型更难个性化

### Existing Methods

现有的FL个性化工作直接采用融合的初始模型，并通过梯度下降进行个性化评估

### Idea

We refer to a trained global model as the initial model, and the locally adapted model as the personalized model.

**Objectives**

1. Improved Personalized Model – for a large majority of the clients
2. Solid Initial Model – some clients have limited or even no data for
3. Fast Convergence – reach a high quality model in small number of training rounds.

### Method

**Definition**: 

For each client $i$, define its local loss function as $L_i(\theta)$

$g_j^i$ be the gradient computed in $j^{th}$  iteration during a local gradient-based optimization process
$$
g FedSGD = \frac{-\beta}{T}\sum_{i=1}^T \frac{\delta L_i(\theta)}{\delta \theta} = \frac{1}{T} \sum_{i=1}^Tg_1^i
$$

$$
\theta_K^i = U_K^i (\theta) = \theta - \beta \sum_{j=1}^K g_j^i  \\
=\theta -\beta \sum_{j=1}^K \frac{\delta L_i(\theta_j)}{\delta \theta}
$$

$$
\frac{\delta U^i_K (\theta)}{\delta \theta} = I - \beta \sum_{j=1}^J \frac{\delta^2 L_i(\theta_j)}{\delta \theta^2}
$$

$$
g MAML = \frac{\delta L_{MAML}}{\delta \theta} = \frac{1}{T} \sum_{i=1}^T 
\frac{\delta L_i(U_K^i(\theta))}{\delta \theta}=\frac{1}{T} \sum_{i=1}^T  
L^{'}_i(U_K^i(\theta))(1-\beta \sum_{j=1}^K \frac{\delta^2 L_I(\theta_j)}{\delta \theta^2})
$$
MAML requires to compute 2nd-order gradients, which can be computationally expensive and creates potentially infeasible memory requirements.


$$
g FedAvg = \frac{1}{T}\sum_{i=1}^T \sum_{j=1}^k g_j^i = \frac{1}{T}\sum_{i=1}^T
g_1^i + \sum_{j=1}^{K-1}\frac{1}{T}\sum_{i=1}^T g^i_{j+1} = gFedSGD + \sum_{j=1}^{K-1}
gFOMAML(j)
$$


1. Run $FedAvg(E)$ with momentum SGD as server optimizer and a relatively larger E. 

2. Switch to $Reptile(K)$ with Adam as server optimizer to fine-tune the initial model. 

3. Conduct personalization with the same client optimizer used during training.

## Think Locally, Act Globally: Federated Learning with Local and Global Representations

### Problem

1. Efficiency 

   使局部模型提取有用的低维表示形式意味着全局模型现在需要较少数量的参数，从而减少了需要与全局模型进行通信的参数和更新的数量，以及通信方面的瓶颈成本

2. Heterogeneity 

   现实世界中的数据通常是异构的（来自不同来源）。 新设备可能包含训练之前从未观察到的数据源，例如个性化移动设备上不同域或不同文本样式的图像。 本地表示使我们能够根据源模式使用专用编码器来处理新设备数据，而不是使用可能无法推广到新模式和分布的单一全局模型。 我们证明了我们的模型从现实世界的私人移动数据中学习个性化的情绪预测因子，并更好地处理了训练期间从未见过的异构数据。

3. Fairness

   现实世界中的数据通常包含敏感属性，最近的研究表明，无需访问数据本身即可从数据表示中恢复这些属性。 我们表明，可以修改本地模型以学习使混淆的种族，年龄和性别等受保护属性变得模糊的公平表示形式，这对于保护设备上数据的隐私至关重要。

### Idea

$(X_m,Y_m)$ represents data on device $m$

$H_m$ are learned local representations via local model $\mathcal{l}_m(\cdot,\theta_m^l):x \rightarrow h$ 

(optional) auxiliary models $a_m(\cdot,\theta_m^a):h \rightarrow z$:

$g(\cdot;\theta^g):h \rightarrow y$ is the global model

AGG is an aggregation function over local updates to the global model.
$$
\theta_m^\mathcal{l} \leftarrow \theta_m^\mathcal{l} - \eta_{\theta_m^\mathcal{l}} \mathcal{L}^g_m (\theta_m^\mathcal{l},\theta_m^\mathcal{g})
$$

$$
\theta_m^\mathcal{g} \leftarrow \theta_m^\mathcal{g} - \eta_{\theta_m^\mathcal{l}} \mathcal{L}^g_m (\theta_m^\mathcal{l},\theta_m^\mathcal{g})
$$

$$
\theta^{g(t+1)} \leftarrow \sum_{m=1}^M \frac{N_m}{N}\theta_m^{g(t+1)}
$$

### Theoretical Analysis

1. purely local models do not suffer from device variance but suffer from data variance

2. the opposite holds true for purely global models  
3. having both local and global models achieves a balance between both desiderata

Goal: Train a network $f_{\widehat{u}}$ with weight $\widehat{u} \in R^d$

To adapt this setting for federated learning, we assume that all device share some underlying structure (e.g. natural syntactic and semantic structures in text) while also displaying personalization across users (e.g. personalized vocabularies and writing styles).



The global feature vector v that represents shared features across devices.

Local features $r_m$ that represent differences across devices.

 The labels on device m are generated by a local teacher with weights:
$$
u_m= v+r_m \in R^d
$$


$r_m \sim \mathcal{N}(0,\rho^2 I)$ is a different independent draw from a  $d$-dimensional Gaussian with covariance of $\rho^2$ .

$\rho^2$ represents device variance: with higher $\rho^2$, the local features differ more representing more personalized targets across devices

## Private Federated Learning with Domain Adaptation

### Problems

- Introducing “noise” in the training process (inputs, parameters, or outputs) makes it difficult to guarantee whether any particular data point was used to train the model. While this noise ensures $\epsilon$-differential privacy for the data point, **it can degrade the accuracy of model predictions.**
- There exists a large body ofwork on domain adaptation in non-FL systems. In domain adaptation, a model trained over a data set from a source domain is further refined to adapt to a data set from a different target domain.

### Idea

$M_G$ is general model with parameters $\Theta_G$, and $\widehat{y}_G = M_G(x,\Theta_G)$

$M_G$ is shared between all parties, and is trained on all data using FL with differentially private SGD (1), enabling each party contribute to training the general model.
$M_P$ be a private model of party $i$, parameterized by $\Theta_{P_i}$, and $\widehat{y}_{P_i} = M_{P_i}(x,\Theta_{P_i})$

$M_{P_i}$ could have a different architecture from $M_G$


$$
\widehat{y}_i = \alpha_i M_G (x,\Theta_G)+(1-\alpha_i(x))M_{P_i}(x,\Theta_{P_i})
$$
$\alpha_i(x)$ is called a gating function in the MoE literature.
$$
\alpha_i(x)  = \sigma (w_i^T \cdot x + b+i)
$$
whether to trust the general model or the private model more for a given input, and the private model $M_{P_i}$ needs to perform well on only the sub-set of points for which the general model fails.

 这意味着具有异常域的用户对通用模型的影响较小，这可能会增强通用模型的能力。 这也可以为用户的数据提供更多的隐私。

